{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34b66c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f7f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unstructured\n",
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f565b905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.15\n"
     ]
    }
   ],
   "source": [
    "print(version(\"unstructured\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d200c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureOpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    print(\"AzureOpenAI API key loaded successfully\")\n",
    "else:\n",
    "    print(\"API KEY not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2593652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\data_parsing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.docx import partition_docx\n",
    "from unstructured.partition.xlsx import partition_xlsx\n",
    "from unstructured.partition.pptx import partition_pptx\n",
    "from unstructured.partition.image import partition_image\n",
    "\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.chunking.basic import chunk_elements\n",
    "\n",
    "from unstructured.documents.elements import (\n",
    "    Title,\n",
    "    NarrativeText,\n",
    "    Table,\n",
    "    ListItem,\n",
    "    Image,\n",
    "    Header,\n",
    "    Footer,\n",
    "    Text,\n",
    "    ElementMetadata\n",
    ")\n",
    "\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb6f2044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Title: 1. Overview\n",
      "------------------------------------------------------------\n",
      "[2] NarrativeText: Document parsing is the process of analyzing and extracting structured information from various docu...\n",
      "------------------------------------------------------------\n",
      "[3] Title: 1.1 Key Benefits\n",
      "------------------------------------------------------------\n",
      "[4] ListItem: Automated data extraction\n",
      "------------------------------------------------------------\n",
      "[5] ListItem: Structured content analysis\n",
      "------------------------------------------------------------\n",
      "[6] ListItem: Integration with AI/ML pipelines\n",
      "------------------------------------------------------------\n",
      "[7] ListItem: Support for multiple formats\n",
      "------------------------------------------------------------\n",
      "[8] Title: 2. Core Features\n",
      "------------------------------------------------------------\n",
      "[9] NarrativeText: Modern document parsers offer a variety of features:\n",
      "------------------------------------------------------------\n",
      "[10] Table: Feature Description Use Case OCR Support Optical Character Recognition for scanned documents Scanned...\n",
      "------------------------------------------------------------\n",
      "[11] Title: 3. Applications in RAG Systems\n",
      "------------------------------------------------------------\n",
      "[12] NarrativeText: Retrieval-Augmented Generation (RAG) systems benefit significantly from proper document parsing:\n",
      "------------------------------------------------------------\n",
      "[13] ListItem: Knowledge Base Creation: Convert documents into searchable chunks\n",
      "------------------------------------------------------------\n",
      "[14] ListItem: Semantic Search: Enable meaning-based document retrieval\n",
      "------------------------------------------------------------\n",
      "[15] ListItem: Question Answering: Provide accurate answers from document context\n",
      "------------------------------------------------------------\n",
      "[16] ListItem: Document Summarization: Generate concise summaries\n",
      "------------------------------------------------------------\n",
      "[17] NarrativeText: \"Effective document parsing is the foundation of any successful RAG implementation.\"\n",
      "------------------------------------------------------------\n",
      "[18] Title: 4. Code Example\n",
      "------------------------------------------------------------\n",
      "[19] NarrativeText: Here's a simple example of using a document parser:\n",
      "------------------------------------------------------------\n",
      "[20] NarrativeText: \n",
      "from docling.document_converter import DocumentConverter\n",
      "\n",
      "# Initialize the converter\n",
      "converter ...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "html_path = 'sample_documents\\sample.html'\n",
    "elements = partition(html_path)\n",
    "\n",
    "for i, element in enumerate(elements,1):\n",
    "    element_type = type(element).__name__\n",
    "    text_preview = element.text[:100]+\"...\" if len(element.text)> 100 else element.text\n",
    "    print(f\"[{i}] {element_type}: {text_preview}\")\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d606e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element Text: \n",
      "1. Overview\n",
      "------------------------------------------------------------\n",
      "Element Metadata: \n",
      "<unstructured.documents.elements.ElementMetadata object at 0x000001FE16BBF750>\n",
      "   category_depth: 1\n",
      "   last_modified: 2025-12-30T05:14:11\n",
      "   languages: ['eng']\n",
      "   file_directory: sample_documents\n",
      "   filename: sample.html\n",
      "   filetype: text/html\n"
     ]
    }
   ],
   "source": [
    "title_element = [e for e in elements if isinstance(e, Title)]\n",
    "\n",
    "if title_element:\n",
    "    first_title = title_element[0]\n",
    "\n",
    "    print(\"Element Text: \")\n",
    "    print(first_title.text)\n",
    "    print('-'*60)\n",
    "\n",
    "    print(\"Element Metadata: \")\n",
    "    meta_data = first_title.metadata\n",
    "\n",
    "    print(meta_data)\n",
    "    meta_data_dict = meta_data.to_dict()\n",
    "    for key, value in meta_data_dict.items():\n",
    "        if value is not None:\n",
    "            print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbade8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_elements(elements):\n",
    "    type_count = {}\n",
    "    for element in elements:\n",
    "        element_type = type(element).__name__\n",
    "        type_count[element_type] = type_count.get(element_type,0) + 1\n",
    "    print(\"Element Distribution: \")\n",
    "    print(\"-\"*30)\n",
    "    for elem_type, count in sorted(type_count.items()):\n",
    "        print(f\"  {elem_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987605ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element Distribution: \n",
      "------------------------------\n",
      "  ListItem: 8\n",
      "  NarrativeText: 6\n",
      "  Table: 1\n",
      "  Title: 5\n"
     ]
    }
   ],
   "source": [
    "type_count = analyze_elements(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e1b6acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 Narrative elements\n",
      "1. Document parsing is the process of analyzing and extracting structured information from various document formats. This includes PDFs, Word documents, HTML pages, and more.\n",
      "\n",
      "2. Modern document parsers offer a variety of features:\n",
      "\n",
      "3. Retrieval-Augmented Generation (RAG) systems benefit significantly from proper document parsing:\n",
      "\n",
      "4. \"Effective document parsing is the foundation of any successful RAG implementation.\"\n",
      "\n",
      "5. Here's a simple example of using a document parser:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "narrative_texts = [e for e in elements if isinstance(e, NarrativeText)]\n",
    "print(f\"Found {len(narrative_texts)} Narrative elements\")\n",
    "for i, text in enumerate(narrative_texts[:5],1):\n",
    "    print(f\"{i}. {text.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e26fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 Table elements: \n",
      "\n",
      "Table 1: \n",
      "\n",
      "Feature Description Use Case OCR Support Optical Character Recognition for scanned documents Scanned PDFs, Images Table Extraction Structured table data extraction Financial reports, Data tables Layout Analysis Understanding document structure Academic papers, Legal documents Image Processing Extract and classify images Technical manuals, Presentations\n",
      "\n",
      "HTML representation available in metadata.text_as_html\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "table_elements = [e for e in elements if isinstance(e,Table)]\n",
    "print(f\"Found {len(table_elements)} Table elements: \\n\")\n",
    "for i, table in enumerate(table_elements):\n",
    "    print(f\"Table {i+1}: \\n\")\n",
    "    print(table.text)\n",
    "    print()\n",
    "\n",
    "    if hasattr(table.metadata, 'text_as_html') and table.metadata.text_as_html:\n",
    "        print(\"HTML representation available in metadata.text_as_html\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd5d80",
   "metadata": {},
   "source": [
    "### **Partitioning Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8cc9386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF exist at: sample_documents\\docling_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "os.makedirs(\"sample_documents\", exist_ok=True)\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "pdf_path = \"sample_documents\\docling_paper.pdf\"\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"Downloading PDF from {pdf_url}\")\n",
    "    urllib.request.urlretrieve(pdf_url)\n",
    "    print(f\"Downloaded to {pdf_path}\")\n",
    "else:\n",
    "    print(f\"PDF exist at: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5449e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"Strategy: AUTO (default)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
