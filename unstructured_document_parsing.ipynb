{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34b66c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f7f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unstructured\n",
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f565b905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.15\n"
     ]
    }
   ],
   "source": [
    "print(version(\"unstructured\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d200c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureOpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if os.getenv('AZURE_OPENAI_API_KEY'):\n",
    "    print(\"AzureOpenAI API key loaded successfully\")\n",
    "else:\n",
    "    print(\"API KEY not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2593652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\data_parsing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.docx import partition_docx\n",
    "from unstructured.partition.xlsx import partition_xlsx\n",
    "from unstructured.partition.pptx import partition_pptx\n",
    "from unstructured.partition.image import partition_image\n",
    "\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.chunking.basic import chunk_elements\n",
    "\n",
    "from unstructured.documents.elements import (\n",
    "    Title,\n",
    "    NarrativeText,\n",
    "    Table,\n",
    "    ListItem,\n",
    "    Image,\n",
    "    Header,\n",
    "    Footer,\n",
    "    Text,\n",
    "    ElementMetadata\n",
    ")\n",
    "\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6f2044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Title: 1. Overview\n",
      "------------------------------------------------------------\n",
      "[2] NarrativeText: Document parsing is the process of analyzing and extracting structured information from various docu...\n",
      "------------------------------------------------------------\n",
      "[3] Title: 1.1 Key Benefits\n",
      "------------------------------------------------------------\n",
      "[4] ListItem: Automated data extraction\n",
      "------------------------------------------------------------\n",
      "[5] ListItem: Structured content analysis\n",
      "------------------------------------------------------------\n",
      "[6] ListItem: Integration with AI/ML pipelines\n",
      "------------------------------------------------------------\n",
      "[7] ListItem: Support for multiple formats\n",
      "------------------------------------------------------------\n",
      "[8] Title: 2. Core Features\n",
      "------------------------------------------------------------\n",
      "[9] NarrativeText: Modern document parsers offer a variety of features:\n",
      "------------------------------------------------------------\n",
      "[10] Table: Feature Description Use Case OCR Support Optical Character Recognition for scanned documents Scanned...\n",
      "------------------------------------------------------------\n",
      "[11] Title: 3. Applications in RAG Systems\n",
      "------------------------------------------------------------\n",
      "[12] NarrativeText: Retrieval-Augmented Generation (RAG) systems benefit significantly from proper document parsing:\n",
      "------------------------------------------------------------\n",
      "[13] ListItem: Knowledge Base Creation: Convert documents into searchable chunks\n",
      "------------------------------------------------------------\n",
      "[14] ListItem: Semantic Search: Enable meaning-based document retrieval\n",
      "------------------------------------------------------------\n",
      "[15] ListItem: Question Answering: Provide accurate answers from document context\n",
      "------------------------------------------------------------\n",
      "[16] ListItem: Document Summarization: Generate concise summaries\n",
      "------------------------------------------------------------\n",
      "[17] NarrativeText: \"Effective document parsing is the foundation of any successful RAG implementation.\"\n",
      "------------------------------------------------------------\n",
      "[18] Title: 4. Code Example\n",
      "------------------------------------------------------------\n",
      "[19] NarrativeText: Here's a simple example of using a document parser:\n",
      "------------------------------------------------------------\n",
      "[20] NarrativeText: \n",
      "from docling.document_converter import DocumentConverter\n",
      "\n",
      "# Initialize the converter\n",
      "converter ...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "html_path = 'sample_documents\\sample.html'\n",
    "elements = partition(html_path)\n",
    "\n",
    "for i, element in enumerate(elements,1):\n",
    "    element_type = type(element).__name__\n",
    "    text_preview = element.text[:100]+\"...\" if len(element.text)> 100 else element.text\n",
    "    print(f\"[{i}] {element_type}: {text_preview}\")\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d606e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element Text: \n",
      "1. Overview\n",
      "------------------------------------------------------------\n",
      "Element Metadata: \n",
      "<unstructured.documents.elements.ElementMetadata object at 0x000001D6FE63DFD0>\n",
      "   category_depth: 1\n",
      "   last_modified: 2025-12-30T05:14:11\n",
      "   languages: ['eng']\n",
      "   file_directory: sample_documents\n",
      "   filename: sample.html\n",
      "   filetype: text/html\n"
     ]
    }
   ],
   "source": [
    "title_element = [e for e in elements if isinstance(e, Title)]\n",
    "\n",
    "if title_element:\n",
    "    first_title = title_element[0]\n",
    "\n",
    "    print(\"Element Text: \")\n",
    "    print(first_title.text)\n",
    "    print('-'*60)\n",
    "\n",
    "    print(\"Element Metadata: \")\n",
    "    meta_data = first_title.metadata\n",
    "\n",
    "    print(meta_data)\n",
    "    meta_data_dict = meta_data.to_dict()\n",
    "    for key, value in meta_data_dict.items():\n",
    "        if value is not None:\n",
    "            print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dbade8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_elements(elements):\n",
    "    type_count = {}\n",
    "    for element in elements:\n",
    "        element_type = type(element).__name__\n",
    "        type_count[element_type] = type_count.get(element_type,0) + 1\n",
    "    print(\"Element Distribution: \")\n",
    "    print(\"-\"*30)\n",
    "    for elem_type, count in sorted(type_count.items()):\n",
    "        print(f\"  {elem_type}: {count}\")\n",
    "    return type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "987605ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element Distribution: \n",
      "------------------------------\n",
      "  ListItem: 8\n",
      "  NarrativeText: 6\n",
      "  Table: 1\n",
      "  Title: 5\n"
     ]
    }
   ],
   "source": [
    "type_count = analyze_elements(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e1b6acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 Narrative elements\n",
      "1. Document parsing is the process of analyzing and extracting structured information from various document formats. This includes PDFs, Word documents, HTML pages, and more.\n",
      "\n",
      "2. Modern document parsers offer a variety of features:\n",
      "\n",
      "3. Retrieval-Augmented Generation (RAG) systems benefit significantly from proper document parsing:\n",
      "\n",
      "4. \"Effective document parsing is the foundation of any successful RAG implementation.\"\n",
      "\n",
      "5. Here's a simple example of using a document parser:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "narrative_texts = [e for e in elements if isinstance(e, NarrativeText)]\n",
    "print(f\"Found {len(narrative_texts)} Narrative elements\")\n",
    "for i, text in enumerate(narrative_texts[:5],1):\n",
    "    print(f\"{i}. {text.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19e26fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 Table elements: \n",
      "\n",
      "Table 1: \n",
      "\n",
      "Feature Description Use Case OCR Support Optical Character Recognition for scanned documents Scanned PDFs, Images Table Extraction Structured table data extraction Financial reports, Data tables Layout Analysis Understanding document structure Academic papers, Legal documents Image Processing Extract and classify images Technical manuals, Presentations\n",
      "\n",
      "HTML representation available in metadata.text_as_html\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "table_elements = [e for e in elements if isinstance(e,Table)]\n",
    "print(f\"Found {len(table_elements)} Table elements: \\n\")\n",
    "for i, table in enumerate(table_elements):\n",
    "    print(f\"Table {i+1}: \\n\")\n",
    "    print(table.text)\n",
    "    print()\n",
    "\n",
    "    if hasattr(table.metadata, 'text_as_html') and table.metadata.text_as_html:\n",
    "        print(\"HTML representation available in metadata.text_as_html\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd5d80",
   "metadata": {},
   "source": [
    "### **Partitioning Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8cc9386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF exist at: sample_documents\\docling_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "os.makedirs(\"sample_documents\", exist_ok=True)\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "pdf_path = \"sample_documents\\docling_paper.pdf\"\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"Downloading PDF from {pdf_url}\")\n",
    "    urllib.request.urlretrieve(pdf_url)\n",
    "    print(f\"Downloaded to {pdf_path}\")\n",
    "else:\n",
    "    print(f\"PDF exist at: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5449e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: AUTO (default)\n",
      "============================================================\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Time taken: 2.05 seconds\n",
      "Elements extracted: 276\n",
      "Element Distribution: \n",
      "------------------------------\n",
      "  Footer: 10\n",
      "  ListItem: 4\n",
      "  NarrativeText: 75\n",
      "  Text: 86\n",
      "  Title: 101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Text': 86, 'Title': 101, 'NarrativeText': 75, 'Footer': 10, 'ListItem': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "print(\"Strategy: AUTO (default)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "element_auto = partition(\n",
    "    filename=pdf_path,\n",
    "    strategy=\"auto\"\n",
    ")\n",
    "elapsed_time = time.time()-start_time\n",
    "\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "print(f\"Elements extracted: {len(element_auto)}\")\n",
    "\n",
    "analyze_elements(element_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "559ddd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: FAST (default)\n",
      "============================================================\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Time taken: 1.76 seconds\n",
      "Elements extracted: 276\n",
      "Element Distribution: \n",
      "------------------------------\n",
      "  Footer: 10\n",
      "  ListItem: 4\n",
      "  NarrativeText: 75\n",
      "  Text: 86\n",
      "  Title: 101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Text': 86, 'Title': 101, 'NarrativeText': 75, 'Footer': 10, 'ListItem': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Strategy: FAST (default)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "element_fast = partition(\n",
    "    filename=pdf_path,\n",
    "    strategy=\"fast\"\n",
    ")\n",
    "elapsed_time = time.time()-start_time\n",
    "\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "print(f\"Elements extracted: {len(element_auto)}\")\n",
    "\n",
    "analyze_elements(element_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c757def1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: HI_RES\n",
      "============================================================\n",
      "Note: hi_res strategy uses ML models and may take longer\n",
      "\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Time taken: 56.05 seconds\n",
      "Elements extracted: 341\n",
      "Element Distribution: \n",
      "------------------------------\n",
      "  FigureCaption: 2\n",
      "  Footer: 2\n",
      "  Header: 4\n",
      "  Image: 24\n",
      "  ListItem: 20\n",
      "  NarrativeText: 58\n",
      "  Table: 4\n",
      "  Text: 202\n",
      "  Title: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Strategy: HI_RES\")\n",
    "print(\"=\"*60)\n",
    "print(\"Note: hi_res strategy uses ML models and may take longer\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    element_auto = partition(\n",
    "        filename=pdf_path,\n",
    "        strategy=\"hi_res\"\n",
    "    )\n",
    "    elapsed_time = time.time()-start_time\n",
    "\n",
    "    print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Elements extracted: {len(element_auto)}\")\n",
    "\n",
    "    analyze_elements(element_auto)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5733346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "First 5 elements from AUTO strategy:\n",
      "============================================================\n",
      "[1] Text\n",
      "   4\n",
      "[2] Text\n",
      "   2024\n",
      "[3] Text\n",
      "   2\n",
      "[4] Text\n",
      "   0\n",
      "[5] Text\n",
      "   2\n",
      "\n",
      "============================================================\n",
      "First 5 elements from AUTO strategy:\n",
      "============================================================\n",
      "[1] Text\n",
      "   4 2 0 2 c e D 9\n",
      "[2] Title\n",
      "   ] L C . s c [\n",
      "[3] Text\n",
      "   5 v 9 6 8 9 0 . 8 0 4 2 : v i X r a\n",
      "[4] Title\n",
      "   Docling Technical Report\n",
      "[5] Title\n",
      "   Version 1.0\n"
     ]
    }
   ],
   "source": [
    "def show_first_elements(elements, n=5, strategy_name=\"\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"First {n} elements from {strategy_name} strategy:\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for i, elem in enumerate(elements[:n]):\n",
    "        elem_tp = type(elem).__name__\n",
    "        text = elem.text[:150]+\"...\" if len(elem.text)>150 else elem.text\n",
    "        print(f\"[{i+1}] {elem_tp}\")\n",
    "        print(f\"   {text}\")\n",
    "\n",
    "show_first_elements(element_auto, n=5, strategy_name=\"AUTO\")\n",
    "show_first_elements(element_fast, n=5, strategy_name=\"AUTO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da36b5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "PDF Elements: 276\n",
      "\n",
      "First 3 elements: \n",
      "    - Text: 4 2 0 2 c e D 9...\n",
      "    - Title: ] L C . s c [...\n",
      "    - Text: 5 v 9 6 8 9 0 . 8 0 4 2 : v i X r a...\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "pdf_element = partition_pdf(\n",
    "    filename=pdf_path,\n",
    "    strategy='fast'\n",
    ")\n",
    "print(f\"PDF Elements: {len(pdf_element)}\")\n",
    "print(f\"\\nFirst 3 elements: \")\n",
    "for elem in pdf_element[:3]:\n",
    "    print(f\"    - {type(elem).__name__}: {elem.text[:80]}...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953c84e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "Found 0 tables in the PDF\n"
     ]
    }
   ],
   "source": [
    "pdf_elements = partition_pdf(\n",
    "    filename=pdf_path,\n",
    "    strategy='fast',\n",
    "    include_page_breaks=True\n",
    ")\n",
    "tables = [e for e in pdf_elements if isinstance(e, Table)]\n",
    "print(f\"Found {len(tables)} tables in the PDF\")\n",
    "\n",
    "if tables:\n",
    "    print(f\"First table content: \")\n",
    "    print(tables[0].text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943f5307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents has 10 pages\n",
      "\n",
      "Page 0: 9 elements\n",
      "\n",
      "Page 1: 15 elements\n",
      "\n",
      "Page 2: 19 elements\n"
     ]
    }
   ],
   "source": [
    "pages = {}\n",
    "for elm in pdf_elements:\n",
    "    page_num = elm.metadata.page_number if elm.metadata.page_number else 0\n",
    "    if page_num not in pages:\n",
    "        pages[page_num] = []\n",
    "    pages[page_num].append(elm)\n",
    "print(f\"Documents has {len(pages)} pages\")\n",
    "for page_num in sorted(pages.keys())[:3]:\n",
    "    print(f\"\\nPage {page_num}: {len(pages[page_num])} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41167ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Elements: 20\n",
      "Element Distribution: \n",
      "------------------------------\n",
      "  ListItem: 8\n",
      "  NarrativeText: 6\n",
      "  Table: 1\n",
      "  Title: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Title': 5, 'NarrativeText': 6, 'ListItem': 8, 'Table': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_elements = partition_html(\n",
    "    filename=\"sample_documents\\sample.html\"\n",
    ")\n",
    "print(f\"HTML Elements: {len(html_elements)}\")\n",
    "analyze_elements(html_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b149b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element fetch from URL: 54\n",
      "   - Title: Documentation...\n",
      "   - Image: Docling...\n",
      "   - Image: DS4SD%2Fdocling | Trendshift...\n",
      "   - Image: arXiv...\n",
      "   - Image: PyPI version...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url_element = partition_html(\n",
    "        url=\"https://docling-project.github.io/docling/\"\n",
    "    )\n",
    "    print(f\"Element fetch from URL: {len(url_element)}\")\n",
    "    for elm in url_element[:5]:\n",
    "        print(f\"   - {type(elm).__name__}: {elm.text[:60]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not fetch URL :{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a1bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements from string: 6\n",
      "  - Title: Sample Document\n",
      "  - NarrativeText: This is a paragraph with some bold text.\n",
      "  - ListItem: Item 1\n",
      "  - ListItem: Item 2\n",
      "  - ListItem: Item 3\n",
      "  - Table: Name Value A 100 B 200\n"
     ]
    }
   ],
   "source": [
    "html_content = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "    <h1>Sample Document</h1>\n",
    "    <p>This is a paragraph with some <strong>bold text</strong>.</p>\n",
    "    <ul>\n",
    "        <li>Item 1</li>\n",
    "        <li>Item 2</li>\n",
    "        <li>Item 3</li>\n",
    "    </ul>\n",
    "    <table>\n",
    "        <tr><th>Name</th><th>Value</th></tr>\n",
    "        <tr><td>A</td><td>100</td></tr>\n",
    "        <tr><td>B</td><td>200</td></tr>\n",
    "    </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "elements_from_string = partition_html(\n",
    "    text=html_content\n",
    ")\n",
    "print(f\"Elements from string: {len(elements_from_string)}\")\n",
    "for elem in elements_from_string:\n",
    "    print(f\"  - {type(elem).__name__}: {elem.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a4d13d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown Elements: 44\n",
      "Element Distribution: \n",
      "------------------------------\n",
      "  ListItem: 15\n",
      "  NarrativeText: 12\n",
      "  Table: 2\n",
      "  Text: 1\n",
      "  Title: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Title': 14, 'NarrativeText': 12, 'ListItem': 15, 'Table': 2, 'Text': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_elements = partition_md(filename=\"sample_documents\\sample.md\")\n",
    "\n",
    "print(f\"Markdown Elements: {len(md_elements)}\")\n",
    "analyze_elements(md_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94860d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown Structure:\n",
      "============================================================\n",
      "Title           | Document Parsing Best Practices\n",
      "NarrativeText   | A comprehensive guide to document parsing for RAG systems.\n",
      "Title           | Table of Contents\n",
      "ListItem        | Introduction\n",
      "ListItem        | Supported Formats\n",
      "ListItem        | Parsing Strategies\n",
      "ListItem        | Integration Guide\n",
      "Title           | Introduction\n",
      "NarrativeText   | Document parsing is a critical component in modern AI applications. It enables t...\n",
      "ListItem        | Build searchable knowledge bases\n",
      "ListItem        | Create training datasets for machine learning\n",
      "ListItem        | Enable semantic search and retrieval\n",
      "ListItem        | Power question-answering systems\n",
      "NarrativeText   | Note: The quality of document parsing directly impacts the performance of downst...\n",
      "Title           | Supported Formats\n"
     ]
    }
   ],
   "source": [
    "print(\"Markdown Structure:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for elem in md_elements[:15]:\n",
    "    element_type = type(elem).__name__\n",
    "    text = elem.text[:80]+\"...\" if len(elem.text)>80 else elem.text\n",
    "    print(f\"{element_type:15} | {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30c0e7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements from markdown string: 7\n",
      "  - Title: Main Title\n",
      "  - NarrativeText: This is an introduction paragraph.\n",
      "  - Title: Section 1\n",
      "  - NarrativeText: Here's some content with: - Bullet point 1 - Bullet point 2\n",
      "  - Title: Section 2\n",
      "  - Text: def hello():\n",
      "    print(\"Hello, World!\")\n",
      "  - Table: Column A Column B Value 1 Value 2\n"
     ]
    }
   ],
   "source": [
    "md_string = \"\"\"\n",
    "# Main Title\n",
    "\n",
    "This is an introduction paragraph.\n",
    "\n",
    "## Section 1\n",
    "\n",
    "Here's some content with:\n",
    "- Bullet point 1\n",
    "- Bullet point 2\n",
    "\n",
    "## Section 2\n",
    "\n",
    "```python\n",
    "def hello():\n",
    "    print(\"Hello, World!\")\n",
    "```\n",
    "\n",
    "| Column A | Column B |\n",
    "|----------|----------|\n",
    "| Value 1  | Value 2  |\n",
    "\"\"\"\n",
    "\n",
    "md_string_elements = partition_md(text=md_string)\n",
    "\n",
    "print(f\"Elements from markdown string: {len(md_string_elements)}\")\n",
    "for elem in md_string_elements:\n",
    "    print(f\"  - {type(elem).__name__}: {elem.text[:60]}...\" if len(elem.text) > 60 else f\"  - {type(elem).__name__}: {elem.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "117d9b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample DOCX at: sample_documents/sample1.docx\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from docx import Document as DocxDocument\n",
    "    from docx.shared import Inches\n",
    "    \n",
    "    # Create a new document\n",
    "    doc = DocxDocument()\n",
    "    \n",
    "    # Add content\n",
    "    doc.add_heading('Sample Word Document', 0)\n",
    "    doc.add_paragraph('This is a sample Word document created for testing Unstructured.')\n",
    "    \n",
    "    doc.add_heading('Section 1: Introduction', level=1)\n",
    "    doc.add_paragraph('Unstructured is a powerful library for document parsing.')\n",
    "    \n",
    "    doc.add_heading('Section 2: Features', level=1)\n",
    "    doc.add_paragraph('Key features include:')\n",
    "    \n",
    "    # Add a bulleted list\n",
    "    doc.add_paragraph('Multiple file format support', style='List Bullet')\n",
    "    doc.add_paragraph('OCR capabilities', style='List Bullet')\n",
    "    doc.add_paragraph('Table extraction', style='List Bullet')\n",
    "    \n",
    "    # Add a simple table\n",
    "    table = doc.add_table(rows=3, cols=2)\n",
    "    table.style = 'Table Grid'\n",
    "    cells = table.rows[0].cells\n",
    "    cells[0].text = 'Feature'\n",
    "    cells[1].text = 'Status'\n",
    "    cells = table.rows[1].cells\n",
    "    cells[0].text = 'PDF Support'\n",
    "    cells[1].text = 'Available'\n",
    "    cells = table.rows[2].cells\n",
    "    cells[0].text = 'OCR'\n",
    "    cells[1].text = 'Available'\n",
    "    \n",
    "    # Save the document\n",
    "    docx_path = 'sample_documents/sample1.docx'\n",
    "    doc.save(docx_path)\n",
    "    print(f\"Created sample DOCX at: {docx_path}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"python-docx not installed. Install with: pip install python-docx\")\n",
    "    docx_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529da065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
